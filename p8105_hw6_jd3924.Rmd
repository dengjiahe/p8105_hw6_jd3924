---
title: "p8105_hw6_jd3924"
author: "Jiahe Deng"
date: "2022-12-01"
output: github_document
---

```{r}
library(tidyverse)
library(dplyr)
library(readr)
library(mgcv)
library(modelr)
```
Question2
```{r}
homicides_data = 
  read_csv("homicide-data.csv", na =" ") %>%
  drop_na() %>%
  mutate(
    city_state = str_c(city,state, sep = ","),
    victim_age = as.numeric(victim_age),
    resolved = ifelse(disposition %in% c("Closed without arrest","Open/No arrest"), "unsolved","solved")) %>%
  filter(victim_race %in% c("White", "Black"),
         !city_state %in% c("Tulsa,AL","Dallas,TX","Phoenix,AZ","Kansas City,MO"),
         victim_age != "Unknown")


homicides_data
```
```{r}
baltimore_df = 
  homicides_data %>%
  filter(city_state == "Baltimore,MD")
baltimore_df
```
```{r}
fit_logistic = 
  baltimore_df %>% 
  mutate(resolved = ifelse(resolved == "solved", 1, 0)) %>%
  glm(resolved ~ victim_age + victim_sex + victim_race, data = ., family = binomial())

fit_logistic %>% 
  broom::tidy() %>% 
  mutate(OR = exp(estimate),
         lower = exp(estimate - 1.96 * std.error),
         upper = exp(estimate + 1.96 * std.error)) %>%
  select(term, estimate, OR, lower, upper, p.value) %>%
  knitr::kable(digits = 3)
```


```{r}
glm_cities = 
  homicides_data %>%
  mutate(
      resolved = ifelse(resolved == "solved", 1, 0)
  ) %>%
  nest(data = -city_state) %>%
  mutate(
    models = map(data, ~glm(resolved ~ victim_age + victim_race + victim_sex, data = .x, family = binomial())),
  results = map(models, broom::tidy)) %>% 
  select(-data, -models) %>% 
  unnest(results)

glm_cities = 
  glm_cities %>% 
  mutate(OR = exp(estimate),
         lower = exp(estimate - 1.96 * std.error),
         upper = exp(estimate + 1.96 * std.error)) %>%
  select(city_state, term, estimate, OR, lower, upper, p.value)
glm_cities
```

```{r}
male_vs_female = 
  glm_cities %>%
  filter(term == "victim_sexMale") %>%
  mutate(city_state = fct_reorder(city_state, OR)) %>%
  ggplot(aes(x = city_state, y = OR)) +
  geom_point() + 
  geom_errorbar(aes(ymin = lower, ymax = upper)) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(
    x = "city,state",
    y = "estimated OR",
    title = "estimated OR and CIs for solving homicides comparing victims on gender"
  )
male_vs_female
```
when all other variables fixed, homicides with male victims are relatively less likely to be resolved than homicides with female victims in all cities.And city Albuquerque,NM has the highest odd ratio. And New York has the lowest odd ratio, also it confidence interval does not contain 1.

Question3
```{r}
birthweight = 
  read_csv("birthweight.csv") %>%
  janitor::clean_names() %>%
  drop_na() %>%
  mutate(
    babysex = as.factor(babysex),
    frace = as.factor(frace),
    malform = as.factor(malform),
    mrace = as.factor(mrace))
birthweight
```
```{r}
map(birthweight, ~ sum(is.na(.)))
```
There is no NA in the dataset. 
```{r}
model_fit = lm(bwt ~ ., data = birthweight)
summary(model_fit)
```
Apply lm to all variable in the data, and check their p_value, and choose only those are significant. 
Significant variable are babysex2, bhead, blength, gaweeks, mrace2, parity, and smoken.
Then, we need to test the assumption of linear regresson.
```{r}
qqnorm(residuals(model_fit), ylab = "residuals")
qqline(residuals(model_fit))
```
From the plot above we can see that the residual follow a normal distribution, which is met the assumpition. 
```{r}
birthweight %>%
  add_residuals(model_fit) %>%
  add_predictions(model_fit) %>%
  ggplot(aes(x = pred, y = resid)) + geom_point(alpha=0.5) +
  geom_smooth(color = "red", method = "lm") +
  labs(
    x = "fitted value",
    y = "residuals"
  )
```
use add_predictions and add_residuals to plot the model residuals against fitted values. From the plot above, we can see that the variances is not a constance, which does not meet the assumption. Thus, we should use glm() instead of lm()

```{r}
glm(bwt ~ babysex + bhead + blength + gaweeks + mrace + parity + smoken, data = birthweight) %>%
  broom::tidy() %>% knitr::kable(digits = 3)
```
```{r}
glm(bwt ~ blength + gaweeks, data = birthweight)
```
```{r}
glm(bwt ~ bhead * blength * babysex, data = birthweight)
```
```{r}
cv_df = 
  crossv_mc(birthweight, 100) %>% 
   mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))
cv_df

```
```{r}
cv_df = 
  cv_df %>% 
  mutate(
    mod1 = map(train, ~glm(bwt ~ babysex + bhead + blength + gaweeks + mrace + parity + smoken, data = .x)),
    mod2 = map(train, ~glm(bwt ~ blength + gaweeks, data = .x)),
    mod3 = map(train, ~glm(bwt ~ bhead * blength * babysex, data =.x))) %>%
  mutate(
    rmse_mod1 = map2_dbl(.x=mod1, .y=test, ~rmse(model = .x, data = .y)),
    rmse_mod2 = map2_dbl(.x=mod2, .y=test, ~rmse(model = .x, data = .y)),
    rmse_mod3 = map2_dbl(.x=mod3, .y=test, ~rmse(model = .x, data = .y)))
cv_df
```
```{r}
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```
Among these model, mod 1 is the best among these three model because it has lowest rmse.


